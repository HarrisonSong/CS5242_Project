{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from keras import *\n",
    "from keras.layers import *\n",
    "from keras import regularizers\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "from keras.callbacks import LearningRateScheduler, TensorBoard\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "df_train = pd.read_csv(\"train.csv\",header=None,delimiter=',',dtype='float64',names=list(range(4096))).fillna(0)\n",
    "X_train = df_train.get_values()\n",
    "df_label = pd.read_csv(\"train_label.csv\",delimiter=',')\n",
    "Y_train = df_label['category'].get_values()\n",
    "Y_train = Y_train.reshape(-1,1)\n",
    "print(X_train.shape)\n",
    "maxlen = 4096\n",
    "embed_size = 128\n",
    "def scheduler(epoch):\n",
    "    if epoch%1==0 and epoch!=0:\n",
    "        lr = K.get_value(model.optimizer.lr)\n",
    "        K.set_value(model.optimizer.lr, lr*.5)\n",
    "        print(\"lr changed to {}\".format(lr*.5))\n",
    "    return K.get_value(model.optimizer.lr)\n",
    "\n",
    "lr_decay = LearningRateScheduler(scheduler)\n",
    "\n",
    "main_input = Input(shape=(maxlen,), dtype='float64',name='main_input')\n",
    "emb = Embedding(256, embed_size, input_length=maxlen,embeddings_regularizer=regularizers.l2(1e-4))(main_input)\n",
    "x = Flatten()(emb)\n",
    "\n",
    "num_layers = 4\n",
    "for i in range(num_layers):\n",
    "    W_reg = regularizers.l2(1e-4)\n",
    "    if i == 0:\n",
    "        W_reg = regularizers.l2(10-4)\n",
    "    x = Dense(10, activation='linear',kernel_regularizer=regularizers.l2(1e-4))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ELU()(x)\n",
    "    #if i == num_layers-1:\n",
    "        #x = DeCovRegularization(0.1)(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    loss_out = Dense(1, activation='sigmoid',name='loss_out')(x)\n",
    "model = Model(input=[main_input], output=[loss_out])\n",
    "optimizer = Adam(lr=0.001)#RMSprop(lr=0.01)#\n",
    "model.compile(optimizer, loss='binary_crossentropy',metrics=['mse', 'accuracy'])\n",
    "\n",
    "model.fit(x=X_train, y=Y_train, batch_size=200, epochs=4, verbose=1, callbacks=[lr_decay], validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None)\n",
    "\n",
    "x_test = pd.read_csv(\"test.csv\",header=None,delimiter=',',dtype='float64',names=list(range(4096))).fillna(0)\n",
    "X_test = df_train.get_values()\n",
    "print(x_test.shape)\n",
    "\n",
    "y=model.predict(x_test, batch_size=None, verbose=0, steps=None)\n",
    "y[y>=0.5]=1\n",
    "y=y.astype(int)\n",
    "print(y.shape[0])\n",
    "\n",
    "s=np.arange(y.shape[0])\n",
    "a= np.zeros((y.shape[0],2)) \n",
    "a= np.vstack([s,y.reshape(-1)])\n",
    "print(a.T)\n",
    "np.savetxt(\"out.csv\", a.T, delimiter=',', fmt='%d', header=\"sample_id,category\", comments=\"\")\n",
    "print(\"finish\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
