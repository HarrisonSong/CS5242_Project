{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:962: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:962: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, TimeDistributed, Flatten\n",
    "from keras.layers import LSTM, Input, Dropout, MaxPooling1D, Conv1D\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras import *\n",
    "from keras.layers import *\n",
    "from keras import regularizers\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "from keras.callbacks import LearningRateScheduler, TensorBoard\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "filepath=\"cnn2para.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='acc',\n",
    "                                            patience=5,\n",
    "                                            verbose=1,\n",
    "                                            factor=0.5,\n",
    "                                            min_lr=0.00001)\n",
    "numpy.random.seed(7)\n",
    "df_train = pd.read_csv(\"train.csv\",header=None,delimiter=',',dtype='float64',names=list(range(4096))).fillna(0)\n",
    "X_train = df_train.get_values()\n",
    "df_label = pd.read_csv(\"train_label.csv\",delimiter=',')\n",
    "Y_train = df_label['category'].get_values()\n",
    "Y_train = Y_train.reshape(-1,1)\n",
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 4096, 8)           2048      \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 4095, 128)         2176      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 2047, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2047, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 2046, 64)          16448     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 1023, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1023, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 65472)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               8380544   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 8,401,345\n",
      "Trainable params: 8,401,345\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# load the dataset but only keep the top n words, zero the rest\n",
    "top_words = 256\n",
    "# truncate and pad input sequences\n",
    "max_review_length = 4096\n",
    "embedding_vecor_length = 8\n",
    "x = Input(shape = (max_review_length, ))\n",
    "y = Embedding(top_words, embedding_vecor_length, input_length=max_review_length)(x)\n",
    "# model.add(TimeDistributed(1000, input_shape=(max_review_length,)))\n",
    "# model.add(LSTM(100, return_sequences=True, input_shape = (max_review_length, 1)))\n",
    "y = Conv1D(filters=128, kernel_size=2, padding='valid', activation='relu')(y)\n",
    "y = MaxPooling1D(pool_size=2)(y)\n",
    "y = Dropout(0.5)(y)\n",
    "y = Conv1D(filters=64, kernel_size=2, padding='valid', activation='relu')(y)\n",
    "y = MaxPooling1D(pool_size=2)(y)\n",
    "y = Dropout(0.5)(y)\n",
    "\n",
    "y = Flatten()(y)\n",
    "y = Dense(128, activation='relu')(y)\n",
    "#y = Dropout(0.5)(y)\n",
    "y = Dense(1, activation='sigmoid')(y)\n",
    "model = Model(inputs=x, outputs=y)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['mse', 'accuracy'])\n",
    "print(model.summary())\n",
    "#model.fit(X_train, Y_train, epochs=5,batch_size=512, verbose=1, callbacks = [learning_rate_reduction])\n",
    "# Final evaluation of the model\n",
    "#X_test = pd.read_csv(\"test.csv\",header=None,delimiter=',',dtype='float64',names=list(range(4096))).fillna(0)\n",
    "#y=model.predict(X_test, batch_size=None, verbose=0, steps=None)\n",
    "#print(y.shape[0])\n",
    "\n",
    "#s=np.arange(y.shape[0])\n",
    "#a= np.zeros((y.shape[0],2))\n",
    "#a= np.vstack([s,y.reshape(-1)])\n",
    "#print(a.T)\n",
    "#np.savetxt(\"out.csv\", a.T, delimiter=',', fmt='%i,%f', header=\"sample_id,malware\", comments=\"\")\n",
    "#print(\"finish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
