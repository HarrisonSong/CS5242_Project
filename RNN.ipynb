{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import matplotlib.pyplot as plt\n",
    "from keras.layers import Embedding, ELU, Dropout, Flatten, Input, Dense, BatchNormalization, Conv1D, MaxPooling1D, LSTM\n",
    "from keras.layers import concatenate, multiply\n",
    "from keras.layers import TimeDistributed, Reshape, RepeatVector, Lambda, Activation\n",
    "from keras.regularizers import l2, l1_l2\n",
    "from keras.optimizers import Adam, Nadam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import backend as K\n",
    "from keras import Model\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import csv\n",
    "\n",
    "# train_dict = {}\n",
    "# train_index_dict = {}\n",
    "# train_label_dict = {}\n",
    "# with open('sample_data.csv', 'rb') as f:\n",
    "#     index = 0\n",
    "#     for sequence in f:\n",
    "#         row = sequence.decode(\"utf-8\")\n",
    "#         seq_list = row.rstrip().split(',')\n",
    "#         size = len(seq_list)\n",
    "#         if size not in train_dict:\n",
    "#             train_dict[size] = []\n",
    "#             train_index_dict[size] = []\n",
    "#         train_dict[size].append(seq_list)\n",
    "#         train_index_dict[size].append(index)\n",
    "#         index += 1\n",
    "        \n",
    "# for size in train_dict.keys():\n",
    "#     train_dict[size] = np.array(train_dict[size])\n",
    "\n",
    "# label = pd.read_csv('sample_label.csv')['category'].values.reshape(-1, 1)\n",
    "# for size in train_index_dict.keys():\n",
    "#     train_label_dict[size] = label[train_index_dict[4096]]\n",
    "        \n",
    "data = pd.read_csv('sample_data.csv',header=None,dtype='float',names=list(range(4096)))\n",
    "test = pd.read_csv('sample_data.csv',header=None,dtype='float',names=list(range(4096)))\n",
    "label = pd.read_csv('sample_label.csv')['category'].values.reshape(-1, 1)\n",
    "\n",
    "print(data.head)\n",
    "print(label.shape)\n",
    "print(test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen=4096\n",
    "embed_size=16\n",
    "lstm_layer_size = 100\n",
    "num_layers = 3\n",
    "\n",
    "main_input = Input(shape=(None,), name='main_input')\n",
    "emb = Embedding(256, embed_size, input_length=maxlen, embeddings_regularizer=l2(1e-4))(main_input)\n",
    "emb = Dropout(0.2)(emb)\n",
    "conv = Conv1D(filters=32, kernel_size=3, padding='same', activation='relu')(emb)\n",
    "emb = MaxPooling1D(pool_size=2)(conv)\n",
    "\n",
    "hs = [] #hidden states from each LSTM layer stored here \n",
    "lstm = LSTM(lstm_layer_size, dropout=0.2, recurrent_dropout=0.2, kernel_regularizer=l2(1e-5), recurrent_regularizer=l2(1e-5), return_sequences=True)(emb)\n",
    "hs.append(lstm)\n",
    "for l in range(1, num_layers):\n",
    "    hs.append(LSTM(lstm_layer_size, dropout=0.2, recurrent_dropout=0.2, kernel_regularizer=l2(1e-5), recurrent_regularizer=l2(1e-5), return_sequences=True)(hs[-1]))\n",
    "local_states = concatenate(hs)\n",
    "average_active = Lambda(function=lambda x: K.mean(x, axis=1), output_shape=lambda shape: (shape[0],) + shape[2:])(local_states) # this produces h\n",
    "state_size = lstm_layer_size*num_layers \n",
    "\n",
    "# Attention mechanism starts here \n",
    "attn_cntx = concatenate([local_states, RepeatVector(maxlen)(average_active)])\n",
    "attn_cntx = TimeDistributed(Dense(lstm_layer_size, activation='linear', kernel_regularizer=l2(1e-4)))(attn_cntx) \n",
    "attn_cntx = TimeDistributed(BatchNormalization())(attn_cntx) \n",
    "attn_cntx = TimeDistributed(Activation('tanh'))(attn_cntx) \n",
    "attn_cntx = TimeDistributed(Dropout(0.5))(attn_cntx) \n",
    "\n",
    "attn = TimeDistributed(Dense(1, activation='linear', kernel_regularizer=l2(1e-4)))(attn_cntx)\n",
    "attn = Flatten()(attn)\n",
    "attn = Activation('softmax')(attn)\n",
    "attn = Reshape((maxlen, 1))(attn)\n",
    "attn = Lambda(function=lambda x: x, output_shape=lambda shape: (shape[:2] + tuple([state_size])))(attn) # repeats value to make a specific shape\n",
    "\n",
    "final_context = multiply([attn, local_states]) \n",
    "final_context = Lambda(function=lambda x: K.sum(x, axis=1), output_shape=lambda shape: (shape[0],) + shape[2:])(final_context) # eq(2), Ti=1 Î±ihi\n",
    "final_context = Dense(state_size, activation='linear', kernel_regularizer=l2(1e-4))(final_context) \n",
    "final_context = BatchNormalization()(final_context) \n",
    "final_context = Activation('tanh')(final_context) \n",
    "final_context = Dropout(0.5)(final_context) \n",
    "\n",
    "loss_out = Dense(1, activation='sigmoid', name='loss_out')(final_context)\n",
    "model = Model(inputs=[main_input], outputs=[loss_out]) \n",
    "optimizer = Adam(lr=0.001, decay=0.004, clipnorm=1.0) \n",
    "model.compile(optimizer, loss='binary_crossentropy', metrics=['binary_accuracy'])\n",
    "\n",
    "es = EarlyStopping(monitor='binary_accuracy', min_delta=0, patience=0, verbose=0, mode='auto')\n",
    "model.fit(data, label, batch_size=200, epochs=4, verbose=1, callbacks=[es])\n",
    "result = model.predict(test, batch_size=200, verbose=1) \n",
    "prediction = pd.DataFrame({'malware': result[:,0]})\n",
    "prediction.to_csv('prediction_rnn.csv', index=True,header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
